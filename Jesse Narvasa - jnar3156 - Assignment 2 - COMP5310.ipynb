{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "COMP5310 - Assignment 2 - jnar3156.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdtHl01sY1NV"
      },
      "source": [
        "# COMP5318: Assignment Final Stage\n",
        "By: Jesse Serina Narvasa (jnar3156)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt5wIgh2YtDI"
      },
      "source": [
        "## Notebook setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a-LpxlvPzZx",
        "outputId": "a72855ea-76f4-4ed3-9c4d-0507f446bbcb"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from collections import OrderedDict\n",
        "from IPython.display import HTML\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHYWyaZXPzZy"
      },
      "source": [
        "# Static Variables\n",
        "\n",
        "INPUT_DATA_PATH = 'drive/My Drive/Colab Notebooks/data/input/'\n",
        "OUTPUT_DATA_PATH = 'drive/My Drive/Colab Notebooks/data/output/'\n",
        "FILENAMES = ['2019.xlsx', '2018.xlsx', '2017.xlsx', '2016.xlsx', '2015.xlsx', '2014.xlsx', '2013.xlsx', '2012.xls', '2011.xls', '2010.xls', '2009.xls', '2008.xls', '2007.xls', '2006.xls', '2005.xls', '2004.xls', '2003.xls', '2002.xls', '2001.xls']\n",
        "OUTPUT_DATASET_FILE = 'output_clean.xlsx'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "wFsfRE1tPzZy",
        "outputId": "c80ad545-7885-4c87-bec8-bae3f771fda8"
      },
      "source": [
        "# Column headers\n",
        "columns = pd.read_excel(INPUT_DATA_PATH + FILENAMES[0], header=None)\n",
        "columns = columns.loc[0,:].values.tolist()\n",
        "\n",
        "# instantiating an empty dataframe\n",
        "df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# iterating through our files to load all the training data for different years\n",
        "for filename in FILENAMES:\n",
        "    data = pd.read_excel(INPUT_DATA_PATH + filename, index_col=None, header=0)\n",
        "    df = df.append(data, ignore_index=True)\n",
        "\n",
        "# loading our dataframe\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ATP</th>\n",
              "      <th>Location</th>\n",
              "      <th>Tournament</th>\n",
              "      <th>Date</th>\n",
              "      <th>Series</th>\n",
              "      <th>Court</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Round</th>\n",
              "      <th>Best of</th>\n",
              "      <th>Winner</th>\n",
              "      <th>Loser</th>\n",
              "      <th>WRank</th>\n",
              "      <th>LRank</th>\n",
              "      <th>WPts</th>\n",
              "      <th>LPts</th>\n",
              "      <th>W1</th>\n",
              "      <th>L1</th>\n",
              "      <th>W2</th>\n",
              "      <th>L2</th>\n",
              "      <th>W3</th>\n",
              "      <th>L3</th>\n",
              "      <th>W4</th>\n",
              "      <th>L4</th>\n",
              "      <th>W5</th>\n",
              "      <th>L5</th>\n",
              "      <th>Wsets</th>\n",
              "      <th>Lsets</th>\n",
              "      <th>Comment</th>\n",
              "      <th>B365W</th>\n",
              "      <th>B365L</th>\n",
              "      <th>PSW</th>\n",
              "      <th>PSL</th>\n",
              "      <th>MaxW</th>\n",
              "      <th>MaxL</th>\n",
              "      <th>AvgW</th>\n",
              "      <th>AvgL</th>\n",
              "      <th>EXW</th>\n",
              "      <th>EXL</th>\n",
              "      <th>LBW</th>\n",
              "      <th>LBL</th>\n",
              "      <th>SJW</th>\n",
              "      <th>SJL</th>\n",
              "      <th>UBW</th>\n",
              "      <th>UBL</th>\n",
              "      <th>CBW</th>\n",
              "      <th>CBL</th>\n",
              "      <th>IWW</th>\n",
              "      <th>IWL</th>\n",
              "      <th>SBW</th>\n",
              "      <th>SBL</th>\n",
              "      <th>B&amp;WW</th>\n",
              "      <th>B&amp;WL</th>\n",
              "      <th>GBW</th>\n",
              "      <th>GBL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Brisbane</td>\n",
              "      <td>Brisbane International</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>Dimitrov G.</td>\n",
              "      <td>Nishioka Y.</td>\n",
              "      <td>19.0</td>\n",
              "      <td>75</td>\n",
              "      <td>1835.0</td>\n",
              "      <td>701.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>1.36</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.36</td>\n",
              "      <td>3.37</td>\n",
              "      <td>1.42</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.35</td>\n",
              "      <td>3.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Brisbane</td>\n",
              "      <td>Brisbane International</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>Raonic M.</td>\n",
              "      <td>Bedene A.</td>\n",
              "      <td>18.0</td>\n",
              "      <td>67</td>\n",
              "      <td>1855.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>1.18</td>\n",
              "      <td>4.50</td>\n",
              "      <td>1.23</td>\n",
              "      <td>4.68</td>\n",
              "      <td>1.27</td>\n",
              "      <td>4.84</td>\n",
              "      <td>1.22</td>\n",
              "      <td>4.26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Brisbane</td>\n",
              "      <td>Brisbane International</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>Kecmanovic M.</td>\n",
              "      <td>Mayer L.</td>\n",
              "      <td>131.0</td>\n",
              "      <td>56</td>\n",
              "      <td>433.0</td>\n",
              "      <td>895.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1.67</td>\n",
              "      <td>2.32</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.40</td>\n",
              "      <td>1.63</td>\n",
              "      <td>2.28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Brisbane</td>\n",
              "      <td>Brisbane International</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>Millman J.</td>\n",
              "      <td>Sandgren T.</td>\n",
              "      <td>38.0</td>\n",
              "      <td>61</td>\n",
              "      <td>1083.0</td>\n",
              "      <td>814.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>1.40</td>\n",
              "      <td>2.75</td>\n",
              "      <td>1.41</td>\n",
              "      <td>3.13</td>\n",
              "      <td>1.45</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1.40</td>\n",
              "      <td>2.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Brisbane</td>\n",
              "      <td>Brisbane International</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>Uchiyama Y.</td>\n",
              "      <td>Humbert U.</td>\n",
              "      <td>185.0</td>\n",
              "      <td>102</td>\n",
              "      <td>275.0</td>\n",
              "      <td>572.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>2.62</td>\n",
              "      <td>1.44</td>\n",
              "      <td>2.73</td>\n",
              "      <td>1.51</td>\n",
              "      <td>3.26</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.69</td>\n",
              "      <td>1.47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51940</th>\n",
              "      <td>69</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>2001-11-12</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>Kafelnikov Y.</td>\n",
              "      <td>Ivanisevic G.</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.45</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.45</td>\n",
              "      <td>2.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51941</th>\n",
              "      <td>69</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>2001-11-12</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>Kafelnikov Y.</td>\n",
              "      <td>Kuerten G.</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51942</th>\n",
              "      <td>69</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>2001-11-12</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>Grosjean S.</td>\n",
              "      <td>Kafelnikov Y.</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.05</td>\n",
              "      <td>1.70</td>\n",
              "      <td>1.80</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1.667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.95</td>\n",
              "      <td>1.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51943</th>\n",
              "      <td>69</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>2001-11-12</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>Hewitt L.</td>\n",
              "      <td>Ferrero J.C.</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.45</td>\n",
              "      <td>2.55</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>3.200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51944</th>\n",
              "      <td>69</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>2001-11-12</td>\n",
              "      <td>Masters Cup</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>The Final</td>\n",
              "      <td>5</td>\n",
              "      <td>Hewitt L.</td>\n",
              "      <td>Grosjean S.</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.45</td>\n",
              "      <td>2.60</td>\n",
              "      <td>1.30</td>\n",
              "      <td>2.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2.750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.40</td>\n",
              "      <td>2.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51945 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ATP  Location              Tournament       Date  ... B&WW B&WL   GBW   GBL\n",
              "0       1  Brisbane  Brisbane International 2018-12-31  ...  NaN  NaN   NaN   NaN\n",
              "1       1  Brisbane  Brisbane International 2018-12-31  ...  NaN  NaN   NaN   NaN\n",
              "2       1  Brisbane  Brisbane International 2018-12-31  ...  NaN  NaN   NaN   NaN\n",
              "3       1  Brisbane  Brisbane International 2018-12-31  ...  NaN  NaN   NaN   NaN\n",
              "4       1  Brisbane  Brisbane International 2018-12-31  ...  NaN  NaN   NaN   NaN\n",
              "...    ..       ...                     ...        ...  ...  ...  ...   ...   ...\n",
              "51940  69    Sydney             Masters Cup 2001-11-12  ...  NaN  NaN  1.45  2.45\n",
              "51941  69    Sydney             Masters Cup 2001-11-12  ...  NaN  NaN   NaN   NaN\n",
              "51942  69    Sydney             Masters Cup 2001-11-12  ...  NaN  NaN  1.95  1.70\n",
              "51943  69    Sydney             Masters Cup 2001-11-12  ...  NaN  NaN  1.20  3.80\n",
              "51944  69    Sydney             Masters Cup 2001-11-12  ...  NaN  NaN  1.40  2.65\n",
              "\n",
              "[51945 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxPeYmL1PzZ2"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InVoCBefPzZ2"
      },
      "source": [
        "def clean_data_1(df):\n",
        "    '''\n",
        "    Initial cleaning of our dataframe\n",
        "    '''\n",
        "    \n",
        "    # Removing entries where the match was not completed\n",
        "    df = df[df['Comment']=='Completed']\n",
        "    \n",
        "    # Remove Max and Avg Betting Odds columns\n",
        "    df.drop(['MaxW', 'MaxL', 'AvgW', 'AvgL'], axis=1, inplace=True)\n",
        "    \n",
        "    # Creating a new feature consolidating the betting odds\n",
        "    winner_odds_idx = list(range(28,df.shape[1],2))\n",
        "    loser_odds_idx = list(range(29, df.shape[1],2))\n",
        "    df['W_Avg_Odds'] = df.iloc[:, winner_odds_idx].mean(axis=1, skipna=True)\n",
        "    df['L_Avg_Odds'] = df.iloc[:, loser_odds_idx].mean(axis=1, skipna=True)\n",
        "    \n",
        "    # Datatype conversion, changing inconsistent data values to NaN with errors='coerce'\n",
        "    date_columns = ['Date']\n",
        "    numeric_columns = ['WRank', 'LRank', 'WPts', 'LPts', 'W1', 'L1', 'W_Avg_Odds', 'L_Avg_Odds']\n",
        "    df[date_columns] = df[date_columns].apply(pd.to_datetime, errors='coerce')\n",
        "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def restructure_winner_loser(df):\n",
        "    '''\n",
        "    Purpose is to rearrange the dataframe, such that the features are not based on winner and loser,\n",
        "    but structured based on Player and Opponent, where Player is always the person whom is losing the first set\n",
        "    Output df is therefore with a new feature Has_Won, which indicates whether Player has won against Opponent\n",
        "    '''\n",
        "    \n",
        "    # since our dataset is already structured, such that the winner and loser player is arranged for each event\n",
        "    # then we need to create a new dataframe, such that the player behind will be relabelled as Player, and the other as \n",
        "    # Opponent respectively.  We can then provide labels on 0 or 1 for \"has_won\" which will be our new feature\n",
        "    common_cols = ['Date', 'Court', 'Surface', 'Round', 'Best of', 'Winner', 'Loser', 'WRank', 'LRank', 'WPts', 'LPts', 'W1', 'L1', 'W_Avg_Odds', 'L_Avg_Odds']\n",
        "    winner_matches_df = df[common_cols].copy(deep=True)\n",
        "    loser_matches_df = df[common_cols].copy(deep=True)\n",
        "\n",
        "    winner_matches_df['Has_Won'] = 1\n",
        "    loser_matches_df['Has_Won'] = 0\n",
        "    \n",
        "    winner_matches_df.rename(columns={\n",
        "        'Winner': 'Player',\n",
        "        'Loser': 'Opponent',\n",
        "        'WRank': 'PRank',\n",
        "        'LRank': 'ORank',\n",
        "        'WPts': 'PPts',\n",
        "        'LPts': 'OPts',\n",
        "        'W1': 'P1',\n",
        "        'L1': 'O1',\n",
        "        'W_Avg_Odds': 'P_Avg_Odds',\n",
        "        'L_Avg_Odds': 'O_Avg_Odds'\n",
        "    }, inplace=True)\n",
        "\n",
        "    loser_matches_df.rename(columns={\n",
        "        'Loser': 'Player',\n",
        "        'Winner': 'Opponent',\n",
        "        'LRank': 'PRank',\n",
        "        'WRank': 'ORank',\n",
        "        'LPts': 'PPts',\n",
        "        'WPts': 'OPts',\n",
        "        'L1': 'P1',\n",
        "        'W1': 'O1',\n",
        "        'L_Avg_Odds': 'P_Avg_Odds',\n",
        "        'W_Avg_Odds': 'O_Avg_Odds'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Now that we have the same columns for both winner and loser dataframes, we can now merge it back to training_df\n",
        "    # except this time, each event is represented twice: first where the player is in col \"Player\" and then as \"Opponent\"\n",
        "    # we will then later extract the rows where the player is behind effectively having a dataset where the player behind\n",
        "    # is set as Player, with our classifier (\"has_won\") will then be mixed between 0 or 1, as opposed to our original dataset\n",
        "    df = winner_matches_df.append(loser_matches_df)\n",
        "    df['Set1_Diff'] = df['P1'] - df['O1']\n",
        "    df.drop(['P1', 'O1'], axis=1, inplace=True)\n",
        "\n",
        "    # We only want the rows where the player is behind. We therefore have restored our dataset back to the original row size\n",
        "    df = df[df['Set1_Diff']<0]\n",
        "    \n",
        "    # Further reduction of features by condensing it\n",
        "    df['Rank_Diff'] = df['PRank'] - df['ORank']\n",
        "    df.drop(['PRank', 'ORank'], axis=1, inplace=True)\n",
        "    \n",
        "    df['Pts_Diff'] = df['PPts'] - df['OPts']\n",
        "    df.drop(['PPts', 'OPts'], axis=1, inplace=True)\n",
        "\n",
        "    # Sort the dataframe by date ASC\n",
        "    df.sort_values(by=['Date', 'Round', 'Player'], inplace=True)\n",
        "\n",
        "    # Reset the index\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def create_momentum_feature(df):\n",
        "    '''\n",
        "    Creates the additional feature for Momentum.  This gives an insight to the player's recent form\n",
        "    and adds an extra dimension for our classification model\n",
        "    '''\n",
        "    \n",
        "    # Creating additional feature to show the momentum of the player coming into the game\n",
        "    # This will take into account the past 10 matches of the player and opponent before the current row(event)\n",
        "    df['PMomentum10'] = ''\n",
        "    df['OMomentum10'] = ''\n",
        "\n",
        "    for row in range(0,df.shape[0]):\n",
        "        current_player = df['Player'][row]\n",
        "        current_opponent = df['Opponent'][row]\n",
        "\n",
        "        # Gets the last 10 matches of the player\n",
        "        # Note that you purposely don't want the current match to be included.  This is why we only do slice(row-1),\n",
        "        # and not slice(row), because we want the previous 10 matches - excluding the current one.\n",
        "        dataset = df.loc[slice(row-1),:][(df['Player'] == current_player) | (df['Opponent'] == current_player)].tail(10)\n",
        "        momentum = ((dataset['Player']==current_player).astype(int)*dataset['Has_Won']).sum() + ((dataset['Opponent']==current_player).astype(int)*abs(dataset['Has_Won']-1)).sum()\n",
        "        df['PMomentum10'][row] = momentum\n",
        "\n",
        "        dataset = df.loc[slice(row-1),:][(df['Player'] == current_opponent) | (df['Opponent'] == current_opponent)].tail(10)\n",
        "        momentum = ((dataset['Player']==current_opponent).astype(int)*dataset['Has_Won']).sum() + ((dataset['Opponent']==current_opponent).astype(int)*abs(dataset['Has_Won']-1)).sum()\n",
        "        df['OMomentum10'][row] = momentum\n",
        "        \n",
        "    return df\n",
        "\n",
        "\n",
        "def clean_data_2(df):\n",
        "    '''\n",
        "    Further reduce the number of unnecessary features\n",
        "    '''\n",
        "    \n",
        "    # We now condense the two columns PMomentum10 and OMomentum10 into Momentum10_Diff\n",
        "    df['Momentum10_Diff'] = df['PMomentum10'] - df['OMomentum10']\n",
        "    df.drop(['PMomentum10', 'OMomentum10'], axis=1, inplace=True)\n",
        "    \n",
        "    df.drop(['Player', 'Opponent'], axis=1, inplace=True)\n",
        "    \n",
        "    # Rearrange the columns to make the classifier label the last column for viewing purposes\n",
        "    df = df[[c for c in df if c not in ['Has_Won']] + ['Has_Won']]\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AQpVJfNPzZ2",
        "outputId": "e159cc73-2e21-4b30-f9e6-7d4045c02454"
      },
      "source": [
        "df = clean_data_1(df)\n",
        "df = restructure_winner_loser(df)\n",
        "df = create_momentum_feature(df)\n",
        "df = clean_data_2(df)\n",
        "\n",
        "# Verification of the dataset\n",
        "df.tail(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:119: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:121: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Court</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Round</th>\n",
              "      <th>Best of</th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Pts_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "      <th>Has_Won</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49993</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Quarterfinals</td>\n",
              "      <td>3</td>\n",
              "      <td>2.185</td>\n",
              "      <td>1.720</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49994</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Quarterfinals</td>\n",
              "      <td>3</td>\n",
              "      <td>3.615</td>\n",
              "      <td>1.315</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-5715.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Quarterfinals</td>\n",
              "      <td>3</td>\n",
              "      <td>5.790</td>\n",
              "      <td>1.155</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>-7995.0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>2019-11-02</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>7.375</td>\n",
              "      <td>1.110</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>-8068.0</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>2019-11-03</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>The Final</td>\n",
              "      <td>3</td>\n",
              "      <td>6.155</td>\n",
              "      <td>1.140</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>-8085.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>2019-11-10</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>7.030</td>\n",
              "      <td>1.115</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-6275.0</td>\n",
              "      <td>-5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>2019-11-10</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.305</td>\n",
              "      <td>3.720</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1165.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50000</th>\n",
              "      <td>2019-11-11</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.410</td>\n",
              "      <td>3.070</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1705.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50001</th>\n",
              "      <td>2019-11-11</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.405</td>\n",
              "      <td>3.095</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>6640.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50002</th>\n",
              "      <td>2019-11-12</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>5.420</td>\n",
              "      <td>1.165</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-3520.0</td>\n",
              "      <td>-4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50003</th>\n",
              "      <td>2019-11-12</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>5.340</td>\n",
              "      <td>1.170</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-3920.0</td>\n",
              "      <td>-5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50004</th>\n",
              "      <td>2019-11-13</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>2.115</td>\n",
              "      <td>1.760</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>3880.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50005</th>\n",
              "      <td>2019-11-13</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.780</td>\n",
              "      <td>2.100</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1055.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50006</th>\n",
              "      <td>2019-11-14</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.390</td>\n",
              "      <td>3.160</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2755.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50007</th>\n",
              "      <td>2019-11-14</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.375</td>\n",
              "      <td>3.235</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2355.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50008</th>\n",
              "      <td>2019-11-15</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.845</td>\n",
              "      <td>2.020</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2760.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50009</th>\n",
              "      <td>2019-11-15</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.415</td>\n",
              "      <td>3.005</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>5585.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50010</th>\n",
              "      <td>2019-11-16</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>1.315</td>\n",
              "      <td>3.625</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50011</th>\n",
              "      <td>2019-11-16</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>2.050</td>\n",
              "      <td>1.820</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-2080.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50012</th>\n",
              "      <td>2019-11-17</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>The Final</td>\n",
              "      <td>3</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.865</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1025.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date   Court Surface          Round Best of  P_Avg_Odds  \\\n",
              "49993 2019-11-01  Indoor    Hard  Quarterfinals       3       2.185   \n",
              "49994 2019-11-01  Indoor    Hard  Quarterfinals       3       3.615   \n",
              "49995 2019-11-01  Indoor    Hard  Quarterfinals       3       5.790   \n",
              "49996 2019-11-02  Indoor    Hard     Semifinals       3       7.375   \n",
              "49997 2019-11-03  Indoor    Hard      The Final       3       6.155   \n",
              "49998 2019-11-10  Indoor    Hard    Round Robin       3       7.030   \n",
              "49999 2019-11-10  Indoor    Hard    Round Robin       3       1.305   \n",
              "50000 2019-11-11  Indoor    Hard    Round Robin       3       1.410   \n",
              "50001 2019-11-11  Indoor    Hard    Round Robin       3       1.405   \n",
              "50002 2019-11-12  Indoor    Hard    Round Robin       3       5.420   \n",
              "50003 2019-11-12  Indoor    Hard    Round Robin       3       5.340   \n",
              "50004 2019-11-13  Indoor    Hard    Round Robin       3       2.115   \n",
              "50005 2019-11-13  Indoor    Hard    Round Robin       3       1.780   \n",
              "50006 2019-11-14  Indoor    Hard    Round Robin       3       1.390   \n",
              "50007 2019-11-14  Indoor    Hard    Round Robin       3       1.375   \n",
              "50008 2019-11-15  Indoor    Hard    Round Robin       3       1.845   \n",
              "50009 2019-11-15  Indoor    Hard    Round Robin       3       1.415   \n",
              "50010 2019-11-16  Indoor    Hard     Semifinals       3       1.315   \n",
              "50011 2019-11-16  Indoor    Hard     Semifinals       3       2.050   \n",
              "50012 2019-11-17  Indoor    Hard      The Final       3       2.000   \n",
              "\n",
              "       O_Avg_Odds  Set1_Diff  Rank_Diff  Pts_Diff Momentum10_Diff  Has_Won  \n",
              "49993       1.720       -4.0      -15.0     890.0              -1        0  \n",
              "49994       1.315       -5.0        6.0   -5715.0              -1        0  \n",
              "49995       1.155       -1.0       33.0   -7995.0              -2        0  \n",
              "49996       1.110       -1.0       26.0   -8068.0              -3        0  \n",
              "49997       1.140       -3.0       27.0   -8085.0              -1        0  \n",
              "49998       1.115       -4.0        6.0   -6275.0              -5        0  \n",
              "49999       3.720       -2.0       -2.0    1165.0               4        0  \n",
              "50000       3.070       -1.0       -2.0    1705.0               0        0  \n",
              "50001       3.095       -4.0       -6.0    6640.0               0        0  \n",
              "50002       1.165       -1.0        5.0   -3520.0              -4        0  \n",
              "50003       1.170       -1.0        3.0   -3920.0              -5        1  \n",
              "50004       1.760       -1.0       -3.0    3880.0               0        1  \n",
              "50005       2.100       -3.0        1.0   -1055.0               0        0  \n",
              "50006       3.160       -2.0       -1.0    2755.0               1        0  \n",
              "50007       3.235       -1.0       -3.0    2355.0               2        0  \n",
              "50008       2.020       -2.0       -3.0    2760.0              -1        0  \n",
              "50009       3.005       -1.0       -5.0    5585.0              -1        1  \n",
              "50010       3.625       -3.0       -3.0    2190.0               4        0  \n",
              "50011       1.820       -2.0        2.0   -2080.0               0        0  \n",
              "50012       1.865       -1.0        1.0   -1025.0               0        1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPXCYh21PzZ2"
      },
      "source": [
        "# Exporting our dataset, so we can quickly re-import without having to re-run all the data pre-processing steps\n",
        "df.to_excel(OUTPUT_DATA_PATH + OUTPUT_DATASET_FILE, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCPe3sCGPzZ3"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CttfbfflPzZ3",
        "outputId": "5e576daa-0014-466f-fa73-243ef7bbfc19"
      },
      "source": [
        "# Importing our dataset we've exported out, to make it easier in case of issues\n",
        "df = pd.read_excel(OUTPUT_DATA_PATH + OUTPUT_DATASET_FILE)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Court</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Round</th>\n",
              "      <th>Best of</th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Pts_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "      <th>Has_Won</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-3</td>\n",
              "      <td>929.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>2.183333</td>\n",
              "      <td>1.503333</td>\n",
              "      <td>-3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>3.550000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>-2</td>\n",
              "      <td>76.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>1st Round</td>\n",
              "      <td>3</td>\n",
              "      <td>2.450000</td>\n",
              "      <td>1.383333</td>\n",
              "      <td>-2</td>\n",
              "      <td>63.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50008</th>\n",
              "      <td>2019-11-15</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.845000</td>\n",
              "      <td>2.020000</td>\n",
              "      <td>-2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2760.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50009</th>\n",
              "      <td>2019-11-15</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Round Robin</td>\n",
              "      <td>3</td>\n",
              "      <td>1.415000</td>\n",
              "      <td>3.005000</td>\n",
              "      <td>-1</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>5585.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50010</th>\n",
              "      <td>2019-11-16</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>1.315000</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50011</th>\n",
              "      <td>2019-11-16</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>Semifinals</td>\n",
              "      <td>3</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>1.820000</td>\n",
              "      <td>-2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-2080.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50012</th>\n",
              "      <td>2019-11-17</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>Hard</td>\n",
              "      <td>The Final</td>\n",
              "      <td>3</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1025.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50013 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Court Surface  ... Pts_Diff  Momentum10_Diff  Has_Won\n",
              "0     2001-01-01  Outdoor    Hard  ...      NaN                0        0\n",
              "1     2001-01-01  Outdoor    Hard  ...      NaN                0        0\n",
              "2     2001-01-01  Outdoor    Hard  ...      NaN                0        0\n",
              "3     2001-01-01  Outdoor    Hard  ...      NaN                0        0\n",
              "4     2001-01-01  Outdoor    Hard  ...      NaN                0        0\n",
              "...          ...      ...     ...  ...      ...              ...      ...\n",
              "50008 2019-11-15   Indoor    Hard  ...   2760.0               -1        0\n",
              "50009 2019-11-15   Indoor    Hard  ...   5585.0               -1        1\n",
              "50010 2019-11-16   Indoor    Hard  ...   2190.0                4        0\n",
              "50011 2019-11-16   Indoor    Hard  ...  -2080.0                0        0\n",
              "50012 2019-11-17   Indoor    Hard  ...  -1025.0                0        1\n",
              "\n",
              "[50013 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "pbvNqKsEPzZ3",
        "outputId": "29d4ddf1-07a6-45bb-b2a6-f7f0a09c030a"
      },
      "source": [
        "# Checking how many entries we have for the round type\n",
        "# We might consider to remove this since it may cause overfitting\n",
        "df.groupby(['Round', 'Has_Won']).count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Court</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Best of</th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Pts_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Round</th>\n",
              "      <th>Has_Won</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1st Round</th>\n",
              "      <th>0</th>\n",
              "      <td>18569</td>\n",
              "      <td>18569</td>\n",
              "      <td>18569</td>\n",
              "      <td>18569</td>\n",
              "      <td>18056</td>\n",
              "      <td>18055</td>\n",
              "      <td>18569</td>\n",
              "      <td>18478</td>\n",
              "      <td>13492</td>\n",
              "      <td>18569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4475</td>\n",
              "      <td>4475</td>\n",
              "      <td>4475</td>\n",
              "      <td>4475</td>\n",
              "      <td>4352</td>\n",
              "      <td>4353</td>\n",
              "      <td>4475</td>\n",
              "      <td>4461</td>\n",
              "      <td>3308</td>\n",
              "      <td>4475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">2nd Round</th>\n",
              "      <th>0</th>\n",
              "      <td>11289</td>\n",
              "      <td>11289</td>\n",
              "      <td>11289</td>\n",
              "      <td>11289</td>\n",
              "      <td>11166</td>\n",
              "      <td>11166</td>\n",
              "      <td>11289</td>\n",
              "      <td>11276</td>\n",
              "      <td>8478</td>\n",
              "      <td>11289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2562</td>\n",
              "      <td>2562</td>\n",
              "      <td>2562</td>\n",
              "      <td>2562</td>\n",
              "      <td>2538</td>\n",
              "      <td>2538</td>\n",
              "      <td>2562</td>\n",
              "      <td>2561</td>\n",
              "      <td>1937</td>\n",
              "      <td>2562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">3rd Round</th>\n",
              "      <th>0</th>\n",
              "      <td>2857</td>\n",
              "      <td>2857</td>\n",
              "      <td>2857</td>\n",
              "      <td>2857</td>\n",
              "      <td>2831</td>\n",
              "      <td>2831</td>\n",
              "      <td>2857</td>\n",
              "      <td>2856</td>\n",
              "      <td>2123</td>\n",
              "      <td>2857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>667</td>\n",
              "      <td>667</td>\n",
              "      <td>667</td>\n",
              "      <td>667</td>\n",
              "      <td>663</td>\n",
              "      <td>663</td>\n",
              "      <td>667</td>\n",
              "      <td>667</td>\n",
              "      <td>500</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">4th Round</th>\n",
              "      <th>0</th>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>670</td>\n",
              "      <td>670</td>\n",
              "      <td>671</td>\n",
              "      <td>671</td>\n",
              "      <td>518</td>\n",
              "      <td>671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>182</td>\n",
              "      <td>139</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Quarterfinals</th>\n",
              "      <th>0</th>\n",
              "      <td>3835</td>\n",
              "      <td>3835</td>\n",
              "      <td>3835</td>\n",
              "      <td>3835</td>\n",
              "      <td>3793</td>\n",
              "      <td>3793</td>\n",
              "      <td>3835</td>\n",
              "      <td>3833</td>\n",
              "      <td>2907</td>\n",
              "      <td>3835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>915</td>\n",
              "      <td>915</td>\n",
              "      <td>915</td>\n",
              "      <td>915</td>\n",
              "      <td>907</td>\n",
              "      <td>907</td>\n",
              "      <td>915</td>\n",
              "      <td>914</td>\n",
              "      <td>677</td>\n",
              "      <td>915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Round Robin</th>\n",
              "      <th>0</th>\n",
              "      <td>280</td>\n",
              "      <td>280</td>\n",
              "      <td>280</td>\n",
              "      <td>280</td>\n",
              "      <td>270</td>\n",
              "      <td>270</td>\n",
              "      <td>280</td>\n",
              "      <td>280</td>\n",
              "      <td>239</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Semifinals</th>\n",
              "      <th>0</th>\n",
              "      <td>1924</td>\n",
              "      <td>1924</td>\n",
              "      <td>1924</td>\n",
              "      <td>1924</td>\n",
              "      <td>1897</td>\n",
              "      <td>1897</td>\n",
              "      <td>1924</td>\n",
              "      <td>1923</td>\n",
              "      <td>1440</td>\n",
              "      <td>1924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>495</td>\n",
              "      <td>495</td>\n",
              "      <td>495</td>\n",
              "      <td>495</td>\n",
              "      <td>487</td>\n",
              "      <td>487</td>\n",
              "      <td>495</td>\n",
              "      <td>495</td>\n",
              "      <td>385</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">The Final</th>\n",
              "      <th>0</th>\n",
              "      <td>985</td>\n",
              "      <td>985</td>\n",
              "      <td>985</td>\n",
              "      <td>985</td>\n",
              "      <td>968</td>\n",
              "      <td>968</td>\n",
              "      <td>985</td>\n",
              "      <td>985</td>\n",
              "      <td>745</td>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>243</td>\n",
              "      <td>243</td>\n",
              "      <td>243</td>\n",
              "      <td>243</td>\n",
              "      <td>239</td>\n",
              "      <td>239</td>\n",
              "      <td>243</td>\n",
              "      <td>243</td>\n",
              "      <td>185</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Date  Court  ...  Pts_Diff  Momentum10_Diff\n",
              "Round         Has_Won                ...                           \n",
              "1st Round     0        18569  18569  ...     13492            18569\n",
              "              1         4475   4475  ...      3308             4475\n",
              "2nd Round     0        11289  11289  ...      8478            11289\n",
              "              1         2562   2562  ...      1937             2562\n",
              "3rd Round     0         2857   2857  ...      2123             2857\n",
              "              1          667    667  ...       500              667\n",
              "4th Round     0          671    671  ...       518              671\n",
              "              1          182    182  ...       139              182\n",
              "Quarterfinals 0         3835   3835  ...      2907             3835\n",
              "              1          915    915  ...       677              915\n",
              "Round Robin   0          280    280  ...       239              280\n",
              "              1           64     64  ...        57               64\n",
              "Semifinals    0         1924   1924  ...      1440             1924\n",
              "              1          495    495  ...       385              495\n",
              "The Final     0          985    985  ...       745              985\n",
              "              1          243    243  ...       185              243\n",
              "\n",
              "[16 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UHcfHNslPzZ3",
        "outputId": "08f76a10-ffc1-43cc-98d3-36d0598b02bf"
      },
      "source": [
        "df.groupby(['Court', 'Has_Won']).count()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Round</th>\n",
              "      <th>Best of</th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Pts_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Court</th>\n",
              "      <th>Has_Won</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Indoor</th>\n",
              "      <th>0</th>\n",
              "      <td>7188</td>\n",
              "      <td>7188</td>\n",
              "      <td>7188</td>\n",
              "      <td>7188</td>\n",
              "      <td>7080</td>\n",
              "      <td>7080</td>\n",
              "      <td>7188</td>\n",
              "      <td>7171</td>\n",
              "      <td>5482</td>\n",
              "      <td>7188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1704</td>\n",
              "      <td>1704</td>\n",
              "      <td>1704</td>\n",
              "      <td>1704</td>\n",
              "      <td>1675</td>\n",
              "      <td>1675</td>\n",
              "      <td>1704</td>\n",
              "      <td>1704</td>\n",
              "      <td>1304</td>\n",
              "      <td>1704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Outdoor</th>\n",
              "      <th>0</th>\n",
              "      <td>33222</td>\n",
              "      <td>33222</td>\n",
              "      <td>33222</td>\n",
              "      <td>33222</td>\n",
              "      <td>32571</td>\n",
              "      <td>32570</td>\n",
              "      <td>33222</td>\n",
              "      <td>33131</td>\n",
              "      <td>24460</td>\n",
              "      <td>33222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7899</td>\n",
              "      <td>7899</td>\n",
              "      <td>7899</td>\n",
              "      <td>7899</td>\n",
              "      <td>7756</td>\n",
              "      <td>7757</td>\n",
              "      <td>7899</td>\n",
              "      <td>7883</td>\n",
              "      <td>5884</td>\n",
              "      <td>7899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Date  Surface  Round  ...  Rank_Diff  Pts_Diff  Momentum10_Diff\n",
              "Court   Has_Won                         ...                                      \n",
              "Indoor  0         7188     7188   7188  ...       7171      5482             7188\n",
              "        1         1704     1704   1704  ...       1704      1304             1704\n",
              "Outdoor 0        33222    33222  33222  ...      33131     24460            33222\n",
              "        1         7899     7899   7899  ...       7883      5884             7899\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "9Iue1h8JPzZ3",
        "outputId": "a9df64e2-5a5e-4267-94dd-34476f002716"
      },
      "source": [
        "df.groupby(['Surface', 'Has_Won']).count()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Court</th>\n",
              "      <th>Round</th>\n",
              "      <th>Best of</th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Pts_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Surface</th>\n",
              "      <th>Has_Won</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Carpet</th>\n",
              "      <th>0</th>\n",
              "      <td>1217</td>\n",
              "      <td>1217</td>\n",
              "      <td>1217</td>\n",
              "      <td>1217</td>\n",
              "      <td>1187</td>\n",
              "      <td>1187</td>\n",
              "      <td>1217</td>\n",
              "      <td>1215</td>\n",
              "      <td>640</td>\n",
              "      <td>1217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>274</td>\n",
              "      <td>274</td>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>137</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Clay</th>\n",
              "      <th>0</th>\n",
              "      <td>13167</td>\n",
              "      <td>13167</td>\n",
              "      <td>13167</td>\n",
              "      <td>13167</td>\n",
              "      <td>12913</td>\n",
              "      <td>12912</td>\n",
              "      <td>13167</td>\n",
              "      <td>13136</td>\n",
              "      <td>9448</td>\n",
              "      <td>13167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3073</td>\n",
              "      <td>3073</td>\n",
              "      <td>3073</td>\n",
              "      <td>3073</td>\n",
              "      <td>3019</td>\n",
              "      <td>3020</td>\n",
              "      <td>3073</td>\n",
              "      <td>3067</td>\n",
              "      <td>2257</td>\n",
              "      <td>3073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Grass</th>\n",
              "      <th>0</th>\n",
              "      <td>4572</td>\n",
              "      <td>4572</td>\n",
              "      <td>4572</td>\n",
              "      <td>4572</td>\n",
              "      <td>4511</td>\n",
              "      <td>4511</td>\n",
              "      <td>4572</td>\n",
              "      <td>4563</td>\n",
              "      <td>3372</td>\n",
              "      <td>4572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1074</td>\n",
              "      <td>1074</td>\n",
              "      <td>1074</td>\n",
              "      <td>1074</td>\n",
              "      <td>1059</td>\n",
              "      <td>1059</td>\n",
              "      <td>1074</td>\n",
              "      <td>1069</td>\n",
              "      <td>809</td>\n",
              "      <td>1074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Hard</th>\n",
              "      <th>0</th>\n",
              "      <td>21454</td>\n",
              "      <td>21454</td>\n",
              "      <td>21454</td>\n",
              "      <td>21454</td>\n",
              "      <td>21040</td>\n",
              "      <td>21040</td>\n",
              "      <td>21454</td>\n",
              "      <td>21388</td>\n",
              "      <td>16482</td>\n",
              "      <td>21454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5173</td>\n",
              "      <td>5173</td>\n",
              "      <td>5173</td>\n",
              "      <td>5173</td>\n",
              "      <td>5079</td>\n",
              "      <td>5079</td>\n",
              "      <td>5173</td>\n",
              "      <td>5168</td>\n",
              "      <td>3985</td>\n",
              "      <td>5173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Date  Court  Round  ...  Rank_Diff  Pts_Diff  Momentum10_Diff\n",
              "Surface Has_Won                       ...                                      \n",
              "Carpet  0         1217   1217   1217  ...       1215       640             1217\n",
              "        1          283    283    283  ...        283       137              283\n",
              "Clay    0        13167  13167  13167  ...      13136      9448            13167\n",
              "        1         3073   3073   3073  ...       3067      2257             3073\n",
              "Grass   0         4572   4572   4572  ...       4563      3372             4572\n",
              "        1         1074   1074   1074  ...       1069       809             1074\n",
              "Hard    0        21454  21454  21454  ...      21388     16482            21454\n",
              "        1         5173   5173   5173  ...       5168      3985             5173\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr65rOIdPzZ3"
      },
      "source": [
        "### Further Removing Unnecessary Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-zV7DtjPzZ3"
      },
      "source": [
        "drop_cols = ['Date']\n",
        "\n",
        "# We are dropping Round because some datapoints have really small sample size, and hence might cause overfitting with model\n",
        "# Also helps to keep the data from being sparse and having too many dimensions\n",
        "\n",
        "df.drop(drop_cols, axis=1, inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwYxe-wzPzZ3"
      },
      "source": [
        "### Ensuring we have the right datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB5V0yJRPzZ4",
        "outputId": "cc0a9c3a-38c3-416d-df05-6fc14014d57d"
      },
      "source": [
        "# Ensure that the datatype for our df is right before we start encoding it\n",
        "# Taking note that the following datatypes will have dummy variables auto-encoded\n",
        "# (object, category)\n",
        "\n",
        "print(df.dtypes)\n",
        "print()\n",
        "\n",
        "category_cols = ['Surface', 'Best of', 'Round', 'Court']\n",
        "df[category_cols] = df[category_cols].astype('category')\n",
        "\n",
        "print(df.dtypes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Court               object\n",
            "Surface             object\n",
            "Round               object\n",
            "Best of              int64\n",
            "P_Avg_Odds         float64\n",
            "O_Avg_Odds         float64\n",
            "Set1_Diff            int64\n",
            "Rank_Diff          float64\n",
            "Pts_Diff           float64\n",
            "Momentum10_Diff      int64\n",
            "Has_Won              int64\n",
            "dtype: object\n",
            "\n",
            "Court              category\n",
            "Surface            category\n",
            "Round              category\n",
            "Best of            category\n",
            "P_Avg_Odds          float64\n",
            "O_Avg_Odds          float64\n",
            "Set1_Diff             int64\n",
            "Rank_Diff           float64\n",
            "Pts_Diff            float64\n",
            "Momentum10_Diff       int64\n",
            "Has_Won               int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "goIHsHtVPzZ4",
        "outputId": "d4f27ea6-faef-4374-f8d2-d7b84d48b36d"
      },
      "source": [
        "df_dummies = pd.get_dummies(df, columns=category_cols)\n",
        "df_dummies"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Pts_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "      <th>Has_Won</th>\n",
              "      <th>Surface_Carpet</th>\n",
              "      <th>Surface_Clay</th>\n",
              "      <th>Surface_Grass</th>\n",
              "      <th>Surface_Hard</th>\n",
              "      <th>Best of_3</th>\n",
              "      <th>Best of_5</th>\n",
              "      <th>Round_1st Round</th>\n",
              "      <th>Round_2nd Round</th>\n",
              "      <th>Round_3rd Round</th>\n",
              "      <th>Round_4th Round</th>\n",
              "      <th>Round_Quarterfinals</th>\n",
              "      <th>Round_Round Robin</th>\n",
              "      <th>Round_Semifinals</th>\n",
              "      <th>Round_The Final</th>\n",
              "      <th>Court_Indoor</th>\n",
              "      <th>Court_Outdoor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-3</td>\n",
              "      <td>929.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.183333</td>\n",
              "      <td>1.503333</td>\n",
              "      <td>-3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.550000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>-2</td>\n",
              "      <td>76.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.450000</td>\n",
              "      <td>1.383333</td>\n",
              "      <td>-2</td>\n",
              "      <td>63.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50008</th>\n",
              "      <td>1.845000</td>\n",
              "      <td>2.020000</td>\n",
              "      <td>-2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2760.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50009</th>\n",
              "      <td>1.415000</td>\n",
              "      <td>3.005000</td>\n",
              "      <td>-1</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>5585.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50010</th>\n",
              "      <td>1.315000</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50011</th>\n",
              "      <td>2.050000</td>\n",
              "      <td>1.820000</td>\n",
              "      <td>-2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-2080.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50012</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1025.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50013 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       P_Avg_Odds  O_Avg_Odds  ...  Court_Indoor  Court_Outdoor\n",
              "0             NaN         NaN  ...             0              1\n",
              "1        2.183333    1.503333  ...             0              1\n",
              "2             NaN         NaN  ...             0              1\n",
              "3        3.550000    1.200000  ...             0              1\n",
              "4        2.450000    1.383333  ...             0              1\n",
              "...           ...         ...  ...           ...            ...\n",
              "50008    1.845000    2.020000  ...             1              0\n",
              "50009    1.415000    3.005000  ...             1              0\n",
              "50010    1.315000    3.625000  ...             1              0\n",
              "50011    2.050000    1.820000  ...             1              0\n",
              "50012    2.000000    1.865000  ...             1              0\n",
              "\n",
              "[50013 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMHy9MOuPzZ4",
        "outputId": "8155e727-bbc0-4191-f504-93bbf60c4d74"
      },
      "source": [
        "df_dummies.count()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "P_Avg_Odds             49082\n",
              "O_Avg_Odds             49082\n",
              "Set1_Diff              50013\n",
              "Rank_Diff              49889\n",
              "Pts_Diff               37130\n",
              "Momentum10_Diff        50013\n",
              "Has_Won                50013\n",
              "Surface_Carpet         50013\n",
              "Surface_Clay           50013\n",
              "Surface_Grass          50013\n",
              "Surface_Hard           50013\n",
              "Best of_3              50013\n",
              "Best of_5              50013\n",
              "Round_1st Round        50013\n",
              "Round_2nd Round        50013\n",
              "Round_3rd Round        50013\n",
              "Round_4th Round        50013\n",
              "Round_Quarterfinals    50013\n",
              "Round_Round Robin      50013\n",
              "Round_Semifinals       50013\n",
              "Round_The Final        50013\n",
              "Court_Indoor           50013\n",
              "Court_Outdoor          50013\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "pHeAigWZPzZ4",
        "outputId": "d0edc6fb-046a-4a8e-fce7-1553a62de7fa"
      },
      "source": [
        "# We notice that there is significantly more entries with missing/lacking Pts_Diff compared to Rank_Diff\n",
        "# Since the two attributes are highly correlated anyway, we will drop Pts_Diff\n",
        "\n",
        "df_dummies.drop('Pts_Diff', axis=1, inplace=True)\n",
        "df_dummies.dropna(inplace=True)\n",
        "\n",
        "print(df_dummies.shape)\n",
        "df_dummies.groupby('Has_Won').count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48967, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P_Avg_Odds</th>\n",
              "      <th>O_Avg_Odds</th>\n",
              "      <th>Set1_Diff</th>\n",
              "      <th>Rank_Diff</th>\n",
              "      <th>Momentum10_Diff</th>\n",
              "      <th>Surface_Carpet</th>\n",
              "      <th>Surface_Clay</th>\n",
              "      <th>Surface_Grass</th>\n",
              "      <th>Surface_Hard</th>\n",
              "      <th>Best of_3</th>\n",
              "      <th>Best of_5</th>\n",
              "      <th>Round_1st Round</th>\n",
              "      <th>Round_2nd Round</th>\n",
              "      <th>Round_3rd Round</th>\n",
              "      <th>Round_4th Round</th>\n",
              "      <th>Round_Quarterfinals</th>\n",
              "      <th>Round_Round Robin</th>\n",
              "      <th>Round_Semifinals</th>\n",
              "      <th>Round_The Final</th>\n",
              "      <th>Court_Indoor</th>\n",
              "      <th>Court_Outdoor</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Has_Won</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "      <td>39551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "      <td>9416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         P_Avg_Odds  O_Avg_Odds  ...  Court_Indoor  Court_Outdoor\n",
              "Has_Won                          ...                             \n",
              "0             39551       39551  ...         39551          39551\n",
              "1              9416        9416  ...          9416           9416\n",
              "\n",
              "[2 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJtdC7dYPzZ4"
      },
      "source": [
        "## Model Selection: Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwvqJbmfPzZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f65f446-7087-431a-b5c1-7351fdca8237"
      },
      "source": [
        "# Library imports\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs8T1UKWPzZ4"
      },
      "source": [
        "# Setting our independent variables separate from our label array\n",
        "df_X = df_dummies[[c for c in df_dummies if c not in ['Has_Won']]]\n",
        "df_y = df_dummies['Has_Won']\n",
        "\n",
        "# Transforming our Pandas DataFrame into numpy array\n",
        "df_X = df_X.to_numpy()\n",
        "\n",
        "# Doing the train/test split\n",
        "# N.B. X here is NumPy array, while y is Pandas Series\n",
        "# this means that X has a range index from 0 to N, while y has the original index from df_dummies, which we'll use later\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.25, stratify=df_y)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V0pYAyTPzZ4"
      },
      "source": [
        "def betting_loss(y_true, y_pred, X=df_dummies):\n",
        "    '''\n",
        "    Calculates the loss based on the prediction and actual outcome\n",
        "    INPUT: array for the actual outcome (y_true), array for the predicted outcome (y_pred)\n",
        "    OUTPUT: scalar value indicating the INVERTED profit or loss.  This is inverted for the purposes of it being a minimisation\n",
        "    function.  Therefore, a negative value here will indicate a profit and a positive value will indicate a loss\n",
        "    '''\n",
        "\n",
        "    # Converting y_pred from Pandas series to DataFrame, setting its index to equal y_true, and switching back to Series\n",
        "    y_pred = pd.DataFrame(data=y_pred)\n",
        "    y_pred.set_index(y_true.index, inplace=True)\n",
        "    y_pred = pd.Series(data=y_pred[0], index=y_pred.index)\n",
        "    \n",
        "    # Obtaining the (non-iloc) indices in y_pred for the 3 categories: correct_win, correct_lose, incorrect_guess\n",
        "    revenue_win_idx = list(y_pred[((y_true == y_pred) & (y_true == 1))].index)\n",
        "    revenue_lose_idx = list(y_pred[((y_true == y_pred) & (y_true == 0))].index)\n",
        "    loss_idx = list(y_pred[y_true != y_pred].index)\n",
        "    \n",
        "    # Assuming that we place a $1 bet for each match\n",
        "    #revenue_win = X[revenue_win_idx, np.where(df_dummies.columns.to_numpy() == 'P_Avg_Odds')[0][0]].sum()\n",
        "    revenue_win = X.loc[revenue_win_idx, 'P_Avg_Odds'].sum(axis=0)\n",
        "    # We're setting this to just the length, because we don't know the actual odds of them continuing to win\n",
        "    # since this should in theory be less than their odds before the match, hence being conservative with our estimate\n",
        "    revenue_lose = len(revenue_lose_idx)\n",
        "    loss = - revenue_win - revenue_lose + len(y_pred)\n",
        "    \n",
        "    print(f'Total number of matches: {y_pred.shape[0]}')\n",
        "    #print(f'Total number of correct win: {len(revenue_win_idx)}')\n",
        "    #print(f'Total number of correct loss: {len(revenue_lose_idx)}')\n",
        "    #print(f'Total number of incorrect predictions: {len(loss_idx)}')\n",
        "    #print(f'Revenue from correct win: {revenue_win}')\n",
        "    print(f'Total Loss incurred: {loss}')\n",
        "    \n",
        "    return loss\n",
        "\n",
        "\n",
        "# creating the scorer function here, to be used by GridSearchCV\n",
        "betting_scorer = make_scorer(betting_loss, greater_is_better=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKxYv0EqPzZ4"
      },
      "source": [
        "def get_best_parameters(classifier_list, X_train, X_test, y_train, y_test):\n",
        "    for classifier in classifier_list:\n",
        "        print(f'Beginning GridSearchCV for {classifier}')\n",
        "        print()\n",
        "        classifier.fit(X_train, y_train)\n",
        "        y_pred = pd.Series(classifier.predict(X_test))\n",
        "        betting_loss(y_test, y_pred)\n",
        "        \n",
        "        # Need to convert it into DataFrame and back to series in order to transfer our index for crosstab\n",
        "        y_pred = pd.DataFrame(data=y_pred)\n",
        "        y_pred.set_index(y_test.index, inplace=True)\n",
        "        y_pred = pd.Series(data=y_pred[0], index=y_pred.index, name='Predicted')\n",
        "        \n",
        "        print(f'Best parameters found {classifier.best_params_}')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(pd.crosstab(y_test, y_pred))\n",
        "        print()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w25CZx7eAbSW"
      },
      "source": [
        "# Setting up our second custom scorer, which we'll be using in addition to to betting_loss scorer\n",
        "f1_score_positive = make_scorer(f1_score, labels=[1], average='binary')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8CBRRDUPzZ4"
      },
      "source": [
        "# Preprocessing functions\n",
        "scaler = StandardScaler()\n",
        "pca = PCA(n_components=0.95, svd_solver='full') # to get explained variance > 95% https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "# Oversampling function\n",
        "smote = SMOTE()\n",
        "\n",
        "# Undersampling function\n",
        "undersampler = RandomUnderSampler()\n",
        "\n",
        "# Classification functions\n",
        "logreg = LogisticRegression(class_weight='balanced', multi_class='ovr', max_iter=1000)\n",
        "rfc = RandomForestClassifier(class_weight='balanced', bootstrap=True)\n",
        "xgc = xgb.XGBClassifier(tree_method='gpu_hist', use_label_encoder=False, booster='gbtree', subsample=0.8)\n",
        "dummy = DummyClassifier(strategy='uniform')\n",
        "dummy.fit(X_train, y_train)\n",
        "\n",
        "# Parameters for each classification function\n",
        "logreg_params = {\n",
        "    'logistic_regression__solver': ['liblinear', 'saga'],\n",
        "    'logistic_regression__penalty': ['l1', 'l2', 'elasticnet']\n",
        "}\n",
        "rfc_params = {\n",
        "    'rfc__criterion': ['gini', 'entropy'],\n",
        "    'rfc__n_estimators': [100, 150, 200],\n",
        "    'rfc__min_samples_split': [2,5,8,11]\n",
        "}\n",
        "xgc_params = {\n",
        "    'xgc__max_depth': [4,5,6,7],\n",
        "    'xgc__learning_rate': [0.01, 0.02],\n",
        "    'xgc__scale_pos_weight': [4]\n",
        "}"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3RL40rMAivx"
      },
      "source": [
        "## Model Selection: Pre-processing Technique **Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoylWGfsPzZ4"
      },
      "source": [
        "### Dataset without standardisation nor PCA applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1NxfKyyPzZ4",
        "outputId": "3dadee1f-8ce1-4720-9ec7-fe3533ef6db8"
      },
      "source": [
        "# Hyperparameter Optimisation Setup\n",
        "\n",
        "# Pipelines for each classification function\n",
        "logreg_pipe = Pipeline([('logistic_regression', logreg)])\n",
        "rfc_pipe = Pipeline([('rfc', rfc)])\n",
        "xgc_pipe = Pipeline([('xgc', xgc)])\n",
        "\n",
        "# GridSearchCV for each classification function\n",
        "logreg_clf = GridSearchCV(logreg_pipe, logreg_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "rfc_clf = GridSearchCV(rfc_pipe, rfc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "xgc_clf = GridSearchCV(xgc_pipe, xgc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Running the GridSearch with CrossValidation\n",
        "get_best_parameters([logreg_clf, rfc_clf, xgc_clf], X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('logistic_regression',\n",
            "                                        LogisticRegression(C=1.0,\n",
            "                                                           class_weight='balanced',\n",
            "                                                           dual=False,\n",
            "                                                           fit_intercept=True,\n",
            "                                                           intercept_scaling=1,\n",
            "                                                           l1_ratio=None,\n",
            "                                                           max_iter=1000,\n",
            "                                                           multi_class='ovr',\n",
            "                                                           n_jobs=None,\n",
            "                                                           penalty='l2',\n",
            "                                                           random_state=None,\n",
            "                                                           solver='lbfgs',\n",
            "                                                           tol=0.0001,\n",
            "                                                           verbose=0,\n",
            "                                                           warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'logistic_regression__penalty': ['l1', 'l2',\n",
            "                                                          'elasticnet'],\n",
            "                         'logistic_regression__solver': ['liblinear', 'saga']},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   28.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3189.953216666667\n",
            "Best parameters found {'logistic_regression__penalty': 'l1', 'logistic_regression__solver': 'saga'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.68      0.78      9888\n",
            "           1       0.34      0.67      0.45      2354\n",
            "\n",
            "    accuracy                           0.68     12242\n",
            "   macro avg       0.62      0.68      0.61     12242\n",
            "weighted avg       0.79      0.68      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6752  3136\n",
            "1           771  1583\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('rfc',\n",
            "                                        RandomForestClassifier(bootstrap=True,\n",
            "                                                               ccp_alpha=0.0,\n",
            "                                                               class_weight='balanced',\n",
            "                                                               criterion='gini',\n",
            "                                                               max_depth=None,\n",
            "                                                               max_features='auto',\n",
            "                                                               max_leaf_nodes=None,\n",
            "                                                               max_samples=None,\n",
            "                                                               min_impurity_decrease=0.0,\n",
            "                                                               min_impurity_split=None,\n",
            "                                                               min_samples_leaf=1,\n",
            "                                                               min_samples_split=2,\n",
            "                                                               min_weight_fracti...\n",
            "                                                               oob_score=False,\n",
            "                                                               random_state=None,\n",
            "                                                               verbose=0,\n",
            "                                                               warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
            "                         'rfc__min_samples_split': [2, 5, 8, 11],\n",
            "                         'rfc__n_estimators': [100, 150, 200]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  2.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2349.0661333333337\n",
            "Best parameters found {'rfc__criterion': 'gini', 'rfc__min_samples_split': 11, 'rfc__n_estimators': 200}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      9888\n",
            "           1       0.43      0.37      0.40      2354\n",
            "\n",
            "    accuracy                           0.79     12242\n",
            "   macro avg       0.64      0.63      0.63     12242\n",
            "weighted avg       0.77      0.79      0.78     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          8743  1145\n",
            "1          1480   874\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('xgc',\n",
            "                                        XGBClassifier(base_score=0.5,\n",
            "                                                      booster='gbtree',\n",
            "                                                      colsample_bylevel=1,\n",
            "                                                      colsample_bynode=1,\n",
            "                                                      colsample_bytree=1,\n",
            "                                                      gamma=0,\n",
            "                                                      learning_rate=0.1,\n",
            "                                                      max_delta_step=0,\n",
            "                                                      max_depth=3,\n",
            "                                                      min_child_weight=1,\n",
            "                                                      missing=None,\n",
            "                                                      n_estimators=100,\n",
            "                                                      n_jobs=1, nthread=None,\n",
            "                                                      objective='binary:logistic',\n",
            "                                                      random_state=...\n",
            "                                                      seed=None, silent=None,\n",
            "                                                      subsample=0.8,\n",
            "                                                      tree_method='gpu_hist',\n",
            "                                                      use_label_encoder=False,\n",
            "                                                      verbosity=1))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'xgc__learning_rate': [0.01, 0.02],\n",
            "                         'xgc__max_depth': [4, 5, 6, 7],\n",
            "                         'xgc__scale_pos_weight': [4]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   19.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3215.443299999999\n",
            "Best parameters found {'xgc__learning_rate': 0.02, 'xgc__max_depth': 4, 'xgc__scale_pos_weight': 4}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.68      0.77      9888\n",
            "           1       0.33      0.68      0.45      2354\n",
            "\n",
            "    accuracy                           0.68     12242\n",
            "   macro avg       0.62      0.68      0.61     12242\n",
            "weighted avg       0.79      0.68      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6679  3209\n",
            "1           745  1609\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwSPx2gdq00c",
        "outputId": "e18d6e3d-b9dd-4917-e144-cf08405fefa7"
      },
      "source": [
        "# Obtaining the final scores for each model, after hyperparameter optimisation, with 5-fold cross-validation\n",
        "\n",
        "print(f'Logistic regression score: {np.mean(cross_val_score(logreg_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'Random forest score: {np.mean(cross_val_score(rfc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'XGBoost score: {np.mean(cross_val_score(xgc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic regression score: 0.4462341361710774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random forest score: 0.3949575523487402\n",
            "XGBoost score: 0.4467245089364035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3oIMix3PzZ4"
      },
      "source": [
        "### Dataset with scaling applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YHdSOEo9PzZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6788654f-6391-4d4c-d297-8f6f91912a9d"
      },
      "source": [
        "# Hyperparameter Optimisation Setup\n",
        "\n",
        "# Pipelines for each classification function\n",
        "logreg_pipe = Pipeline([('scale', scaler),\n",
        "                       ('logistic_regression', logreg)])\n",
        "rfc_pipe = Pipeline([('scale', scaler),\n",
        "                    ('rfc', rfc)])\n",
        "xgc_pipe = Pipeline([('scale', scaler),\n",
        "                    ('xgc', xgc)])\n",
        "\n",
        "# GridSearchCV for each classification function\n",
        "logreg_clf = GridSearchCV(logreg_pipe, logreg_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "rfc_clf = GridSearchCV(rfc_pipe, rfc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "xgc_clf = GridSearchCV(xgc_pipe, xgc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Running the GridSearch with CrossValidation\n",
        "get_best_parameters([logreg_clf, rfc_clf, xgc_clf], X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('scale',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('logistic_regression',\n",
            "                                        LogisticRegression(C=1.0,\n",
            "                                                           class_weight='balanced',\n",
            "                                                           dual=False,\n",
            "                                                           fit_intercept=True,\n",
            "                                                           intercept_scaling=1,\n",
            "                                                           l1_ratio=None,\n",
            "                                                           max_iter=1000,\n",
            "                                                           multi_class='ovr',\n",
            "                                                           n_jobs=None,\n",
            "                                                           penalty='l2',\n",
            "                                                           random_state=None,\n",
            "                                                           solver='lbfgs',\n",
            "                                                           tol=0.0001,\n",
            "                                                           verbose=0,\n",
            "                                                           warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'logistic_regression__penalty': ['l1', 'l2',\n",
            "                                                          'elasticnet'],\n",
            "                         'logistic_regression__solver': ['liblinear', 'saga']},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    1.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3255.141466666668\n",
            "Best parameters found {'logistic_regression__penalty': 'l2', 'logistic_regression__solver': 'liblinear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.67      0.77      9888\n",
            "           1       0.33      0.68      0.45      2354\n",
            "\n",
            "    accuracy                           0.67     12242\n",
            "   macro avg       0.61      0.68      0.61     12242\n",
            "weighted avg       0.79      0.67      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6616  3272\n",
            "1           742  1612\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('scale',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('rfc',\n",
            "                                        RandomForestClassifier(bootstrap=True,\n",
            "                                                               ccp_alpha=0.0,\n",
            "                                                               class_weight='balanced',\n",
            "                                                               criterion='gini',\n",
            "                                                               max_depth=None,\n",
            "                                                               max_features='auto',\n",
            "                                                               max_leaf_nodes=None,\n",
            "                                                               max_samples=None,\n",
            "                                                               min_impurity_decrease=0.0,\n",
            "                                                               min_impurity_sp...\n",
            "                                                               oob_score=False,\n",
            "                                                               random_state=None,\n",
            "                                                               verbose=0,\n",
            "                                                               warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
            "                         'rfc__min_samples_split': [2, 5, 8, 11],\n",
            "                         'rfc__n_estimators': [100, 150, 200]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  2.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2325.970316666666\n",
            "Best parameters found {'rfc__criterion': 'gini', 'rfc__min_samples_split': 11, 'rfc__n_estimators': 200}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      9888\n",
            "           1       0.44      0.38      0.41      2354\n",
            "\n",
            "    accuracy                           0.79     12242\n",
            "   macro avg       0.65      0.63      0.64     12242\n",
            "weighted avg       0.78      0.79      0.78     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          8733  1155\n",
            "1          1459   895\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('scale',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('xgc',\n",
            "                                        XGBClassifier(base_score=0.5,\n",
            "                                                      booster='gbtree',\n",
            "                                                      colsample_bylevel=1,\n",
            "                                                      colsample_bynode=1,\n",
            "                                                      colsample_bytree=1,\n",
            "                                                      gamma=0,\n",
            "                                                      learning_rate=0.1,\n",
            "                                                      max_delta_step=0,\n",
            "                                                      max_depth=3,\n",
            "                                                      min_child_weight=1,\n",
            "                                                      missing=None,\n",
            "                                                      n_estimators=10...\n",
            "                                                      seed=None, silent=None,\n",
            "                                                      subsample=0.8,\n",
            "                                                      tree_method='gpu_hist',\n",
            "                                                      use_label_encoder=False,\n",
            "                                                      verbosity=1))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'xgc__learning_rate': [0.01, 0.02],\n",
            "                         'xgc__max_depth': [4, 5, 6, 7],\n",
            "                         'xgc__scale_pos_weight': [4]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   18.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3215.443299999999\n",
            "Best parameters found {'xgc__learning_rate': 0.02, 'xgc__max_depth': 4, 'xgc__scale_pos_weight': 4}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.68      0.77      9888\n",
            "           1       0.33      0.68      0.45      2354\n",
            "\n",
            "    accuracy                           0.68     12242\n",
            "   macro avg       0.62      0.68      0.61     12242\n",
            "weighted avg       0.79      0.68      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6679  3209\n",
            "1           745  1609\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5zp1hGPw9qj",
        "outputId": "c2a2e6b3-687d-4471-e9fa-a250ee365923"
      },
      "source": [
        "# Obtaining the final scores for each model, after hyperparameter optimisation, with 5-fold cross-validation\n",
        "\n",
        "print(f'Logistic regression score: {np.mean(cross_val_score(logreg_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'Random forest score: {np.mean(cross_val_score(rfc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'XGBoost score: {np.mean(cross_val_score(xgc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic regression score: 0.44469191999332247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random forest score: 0.39640504661414505\n",
            "XGBoost score: 0.4467245089364035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3WP0Z3aPzZ4"
      },
      "source": [
        "### Dataset with scaling and PCA applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "T7hLOq_UPzZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa64b192-5f83-47df-e7ed-3227dc78503b"
      },
      "source": [
        "# Pipelines for each classification function\n",
        "logreg_pipe = Pipeline([('scale', scaler),\n",
        "                       ('pca', pca),\n",
        "                       ('logistic_regression', logreg)])\n",
        "rfc_pipe = Pipeline([('scale', scaler),\n",
        "                    ('pca', pca),\n",
        "                    ('rfc', rfc)])\n",
        "xgc_pipe = Pipeline([('scale', scaler),\n",
        "                     ('pca', pca),\n",
        "                     ('xgc', xgc)])\n",
        "\n",
        "# GridSearchCV for each classification function\n",
        "logreg_clf = GridSearchCV(logreg_pipe, logreg_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "rfc_clf = GridSearchCV(rfc_pipe, rfc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "xgc_clf = GridSearchCV(xgc_pipe, xgc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Running the GridSearch with CrossValidation\n",
        "get_best_parameters([logreg_clf, rfc_clf, xgc_clf], X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('scale',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('pca',\n",
            "                                        PCA(copy=True, iterated_power='auto',\n",
            "                                            n_components=0.95,\n",
            "                                            random_state=None,\n",
            "                                            svd_solver='full', tol=0.0,\n",
            "                                            whiten=False)),\n",
            "                                       ('logistic_regression',\n",
            "                                        LogisticRegression(C=1.0,\n",
            "                                                           class_weight='balanced',\n",
            "                                                           dual=False,\n",
            "                                                           fit_interc...\n",
            "                                                           random_state=None,\n",
            "                                                           solver='lbfgs',\n",
            "                                                           tol=0.0001,\n",
            "                                                           verbose=0,\n",
            "                                                           warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'logistic_regression__penalty': ['l1', 'l2',\n",
            "                                                          'elasticnet'],\n",
            "                         'logistic_regression__solver': ['liblinear', 'saga']},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3222.9563333333335\n",
            "Best parameters found {'logistic_regression__penalty': 'l2', 'logistic_regression__solver': 'saga'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.68      0.77      9888\n",
            "           1       0.33      0.65      0.43      2354\n",
            "\n",
            "    accuracy                           0.68     12242\n",
            "   macro avg       0.61      0.67      0.60     12242\n",
            "weighted avg       0.78      0.68      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6767  3121\n",
            "1           833  1521\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('scale',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('pca',\n",
            "                                        PCA(copy=True, iterated_power='auto',\n",
            "                                            n_components=0.95,\n",
            "                                            random_state=None,\n",
            "                                            svd_solver='full', tol=0.0,\n",
            "                                            whiten=False)),\n",
            "                                       ('rfc',\n",
            "                                        RandomForestClassifier(bootstrap=True,\n",
            "                                                               ccp_alpha=0.0,\n",
            "                                                               class_weight='balanced',\n",
            "                                                               criterion=...\n",
            "                                                               oob_score=False,\n",
            "                                                               random_state=None,\n",
            "                                                               verbose=0,\n",
            "                                                               warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
            "                         'rfc__min_samples_split': [2, 5, 8, 11],\n",
            "                         'rfc__n_estimators': [100, 150, 200]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  8.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2400.7606333333333\n",
            "Best parameters found {'rfc__criterion': 'gini', 'rfc__min_samples_split': 11, 'rfc__n_estimators': 150}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      9888\n",
            "           1       0.41      0.30      0.35      2354\n",
            "\n",
            "    accuracy                           0.78     12242\n",
            "   macro avg       0.62      0.60      0.61     12242\n",
            "weighted avg       0.76      0.78      0.77     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          8851  1037\n",
            "1          1644   710\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('scale',\n",
            "                                        StandardScaler(copy=True,\n",
            "                                                       with_mean=True,\n",
            "                                                       with_std=True)),\n",
            "                                       ('pca',\n",
            "                                        PCA(copy=True, iterated_power='auto',\n",
            "                                            n_components=0.95,\n",
            "                                            random_state=None,\n",
            "                                            svd_solver='full', tol=0.0,\n",
            "                                            whiten=False)),\n",
            "                                       ('xgc',\n",
            "                                        XGBClassifier(base_score=0.5,\n",
            "                                                      booster='gbtree',\n",
            "                                                      colsample_bylevel=1,\n",
            "                                                      colsample_bynode=1,\n",
            "                                                      c...\n",
            "                                                      seed=None, silent=None,\n",
            "                                                      subsample=0.8,\n",
            "                                                      tree_method='gpu_hist',\n",
            "                                                      use_label_encoder=False,\n",
            "                                                      verbosity=1))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'xgc__learning_rate': [0.01, 0.02],\n",
            "                         'xgc__max_depth': [4, 5, 6, 7],\n",
            "                         'xgc__scale_pos_weight': [4]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   19.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3232.116249999999\n",
            "Best parameters found {'xgc__learning_rate': 0.02, 'xgc__max_depth': 4, 'xgc__scale_pos_weight': 4}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.69      0.78      9888\n",
            "           1       0.33      0.63      0.43      2354\n",
            "\n",
            "    accuracy                           0.68     12242\n",
            "   macro avg       0.61      0.66      0.60     12242\n",
            "weighted avg       0.78      0.68      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6830  3058\n",
            "1           870  1484\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlRkiaK6xQ29",
        "outputId": "e17e7944-52e1-4937-d5d9-e92ea6ddb5f7"
      },
      "source": [
        "# Obtaining the final scores for each model, after hyperparameter optimisation, with 5-fold cross-validation\n",
        "\n",
        "print(f'Logistic regression score: {np.mean(cross_val_score(logreg_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'Random forest score: {np.mean(cross_val_score(rfc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'XGBoost score: {np.mean(cross_val_score(xgc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic regression score: 0.4357878488091614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   36.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random forest score: 0.3449642571178505\n",
            "XGBoost score: 0.43344348575251457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbmVIhw0AG52"
      },
      "source": [
        "## Model Selection: Handling Imbalanced Data Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkwnnp77PzZ5"
      },
      "source": [
        "### With SMOTE (Oversampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "N48FoKUjPzZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009e9286-504f-439b-fb4b-f87ae7d713ee"
      },
      "source": [
        "# Need to use imblearn's pipeline in this section because scikit learn's pipeline object can't handle SMOTE sample func\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Pipelines for each classification function\n",
        "logreg_pipe = Pipeline([('smote', smote),\n",
        "                       ('logistic_regression', logreg)])\n",
        "rfc_pipe = Pipeline([('smote', smote),\n",
        "                    ('rfc', rfc)])\n",
        "xgc_pipe = Pipeline([('smote', smote),\n",
        "                     ('xgc', xgc)])\n",
        "\n",
        "# Need to reset XGBoost's parameter configuration compared to the one above, since we're removing class weightings\n",
        "xgc_params_over = {\n",
        "    'xgc__max_depth': [4,5,6,7],\n",
        "    'xgc__learning_rate': [0.01, 0.02]\n",
        "}\n",
        "\n",
        "# GridSearchCV for each classification function\n",
        "logreg_clf = GridSearchCV(logreg_pipe, logreg_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "rfc_clf = GridSearchCV(rfc_pipe, rfc_params, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "xgc_clf = GridSearchCV(xgc_pipe, xgc_params_over, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Running the GridSearch with CrossValidation\n",
        "get_best_parameters([logreg_clf, rfc_clf, xgc_clf], X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('smote',\n",
            "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
            "                                              m_neighbors='deprecated',\n",
            "                                              n_jobs=1, out_step='deprecated',\n",
            "                                              random_state=None, ratio=None,\n",
            "                                              sampling_strategy='auto',\n",
            "                                              svm_estimator='deprecated')),\n",
            "                                       ('logistic_regression',\n",
            "                                        LogisticRegression(C=1.0,\n",
            "                                                           class_weight='balanced',\n",
            "                                                           dual=False,\n",
            "                                                           fit_inter...\n",
            "                                                           random_state=None,\n",
            "                                                           solver='lbfgs',\n",
            "                                                           tol=0.0001,\n",
            "                                                           verbose=0,\n",
            "                                                           warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'logistic_regression__penalty': ['l1', 'l2',\n",
            "                                                          'elasticnet'],\n",
            "                         'logistic_regression__solver': ['liblinear', 'saga']},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   39.3s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3281.2941499999997\n",
            "Best parameters found {'logistic_regression__penalty': 'l1', 'logistic_regression__solver': 'saga'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.67      0.77      9888\n",
            "           1       0.33      0.68      0.44      2354\n",
            "\n",
            "    accuracy                           0.67     12242\n",
            "   macro avg       0.61      0.67      0.61     12242\n",
            "weighted avg       0.79      0.67      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6640  3248\n",
            "1           759  1595\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('smote',\n",
            "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
            "                                              m_neighbors='deprecated',\n",
            "                                              n_jobs=1, out_step='deprecated',\n",
            "                                              random_state=None, ratio=None,\n",
            "                                              sampling_strategy='auto',\n",
            "                                              svm_estimator='deprecated')),\n",
            "                                       ('rfc',\n",
            "                                        RandomForestClassifier(bootstrap=True,\n",
            "                                                               ccp_alpha=0.0,\n",
            "                                                               class_weight='balanced',\n",
            "                                                               criterion...\n",
            "                                                               oob_score=False,\n",
            "                                                               random_state=None,\n",
            "                                                               verbose=0,\n",
            "                                                               warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
            "                         'rfc__min_samples_split': [2, 5, 8, 11],\n",
            "                         'rfc__n_estimators': [100, 150, 200]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  4.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2291.721316666666\n",
            "Best parameters found {'rfc__criterion': 'gini', 'rfc__min_samples_split': 11, 'rfc__n_estimators': 200}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88      9888\n",
            "           1       0.45      0.27      0.34      2354\n",
            "\n",
            "    accuracy                           0.80     12242\n",
            "   macro avg       0.65      0.60      0.61     12242\n",
            "weighted avg       0.77      0.80      0.78     12242\n",
            "\n",
            "Predicted     0    1\n",
            "Has_Won             \n",
            "0          9118  770\n",
            "1          1714  640\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('smote',\n",
            "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
            "                                              m_neighbors='deprecated',\n",
            "                                              n_jobs=1, out_step='deprecated',\n",
            "                                              random_state=None, ratio=None,\n",
            "                                              sampling_strategy='auto',\n",
            "                                              svm_estimator='deprecated')),\n",
            "                                       ('xgc',\n",
            "                                        XGBClassifier(base_score=0.5,\n",
            "                                                      booster='gbtree',\n",
            "                                                      colsample_bylevel=1,\n",
            "                                                      colsample_bynode=1,...\n",
            "                                                      scale_pos_weight=1,\n",
            "                                                      seed=None, silent=None,\n",
            "                                                      subsample=0.8,\n",
            "                                                      tree_method='gpu_hist',\n",
            "                                                      use_label_encoder=False,\n",
            "                                                      verbosity=1))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'xgc__learning_rate': [0.01, 0.02],\n",
            "                         'xgc__max_depth': [4, 5, 6, 7]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   19.8s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2998.6607666666678\n",
            "Best parameters found {'xgc__learning_rate': 0.01, 'xgc__max_depth': 4}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.72      0.80      9888\n",
            "           1       0.35      0.63      0.45      2354\n",
            "\n",
            "    accuracy                           0.70     12242\n",
            "   macro avg       0.62      0.67      0.62     12242\n",
            "weighted avg       0.79      0.70      0.73     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          7151  2737\n",
            "1           879  1475\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVe5oRJ7O4qd",
        "outputId": "42f52937-bd8e-4ad3-dcab-5a6e89669956"
      },
      "source": [
        "# Obtaining the final scores for each model, after hyperparameter optimisation, with 5-fold cross-validation\n",
        "\n",
        "print(f'Logistic regression score: {np.mean(cross_val_score(logreg_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'Random forest score: {np.mean(cross_val_score(rfc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'XGBoost score: {np.mean(cross_val_score(xgc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   50.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic regression score: 0.44352121895038515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random forest score: 0.3202076068320464\n",
            "XGBoost score: 0.44371728427733903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SV4vwdBPzZ5"
      },
      "source": [
        "### With SMOTE and Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE6BWBmDPzZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d4932a-07dd-4d4c-d0b2-2a5b9b4dd31f"
      },
      "source": [
        "# Need to use imblearn's pipeline in this section because scikit learn's pipeline object can't handle SMOTE sample func\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Pipelines for each classification function\n",
        "logreg_pipe = Pipeline([('smote', smote),\n",
        "                        ('undersampler', undersampler),\n",
        "                       ('logistic_regression', logreg)])\n",
        "rfc_pipe = Pipeline([('smote', smote),\n",
        "                     ('undersampler', undersampler),\n",
        "                    ('rfc', rfc)])\n",
        "xgc_pipe = Pipeline([('smote', smote),\n",
        "                     ('undersampler', undersampler),\n",
        "                     ('xgc', xgc)])\n",
        "\n",
        "# Need to reset XGBoost's parameter configuration compared to the one above, since we're removing class weightings\n",
        "logreg_params_over_under = {\n",
        "    'smote__sampling_strategy': [0.3, 0.4],\n",
        "    'undersampler__sampling_strategy': [0.5, 0.75],\n",
        "    'logistic_regression__solver': ['liblinear', 'saga'],\n",
        "    'logistic_regression__penalty': ['l1', 'l2', 'elasticnet']\n",
        "}\n",
        "rfc_params_over_under = {\n",
        "    'smote__sampling_strategy': [0.3, 0.4],\n",
        "    'undersampler__sampling_strategy': [0.5, 0.75],\n",
        "    'rfc__criterion': ['gini', 'entropy'],\n",
        "    'rfc__n_estimators': [100, 150, 200],\n",
        "    'rfc__min_samples_split': [2,5,8,11]\n",
        "}\n",
        "xgc_params_over_under = {\n",
        "    'smote__sampling_strategy': [0.3, 0.4],\n",
        "    'undersampler__sampling_strategy': [0.5, 0.75],\n",
        "    'xgc__max_depth': [4,5,6,7],\n",
        "    'xgc__learning_rate': [0.01, 0.02],\n",
        "}\n",
        "\n",
        "# GridSearchCV for each classification function\n",
        "logreg_clf = GridSearchCV(logreg_pipe, logreg_params_over_under, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "rfc_clf = GridSearchCV(rfc_pipe, rfc_params_over_under, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "xgc_clf = GridSearchCV(xgc_pipe, xgc_params_over_under, scoring=f1_score_positive, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Running the GridSearch with CrossValidation\n",
        "get_best_parameters([logreg_clf, rfc_clf, xgc_clf], X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('smote',\n",
            "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
            "                                              m_neighbors='deprecated',\n",
            "                                              n_jobs=1, out_step='deprecated',\n",
            "                                              random_state=None, ratio=None,\n",
            "                                              sampling_strategy='auto',\n",
            "                                              svm_estimator='deprecated')),\n",
            "                                       ('undersampler',\n",
            "                                        RandomUnderSampler(random_state=None,\n",
            "                                                           ratio=None,\n",
            "                                                           replacement=False,\n",
            "                                                           return_ind...\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'logistic_regression__penalty': ['l1', 'l2',\n",
            "                                                          'elasticnet'],\n",
            "                         'logistic_regression__solver': ['liblinear', 'saga'],\n",
            "                         'smote__sampling_strategy': [0.3, 0.4],\n",
            "                         'undersampler__sampling_strategy': [0.5, 0.75]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.1s\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  1.1min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3234.097883333332\n",
            "Best parameters found {'logistic_regression__penalty': 'l1', 'logistic_regression__solver': 'saga', 'smote__sampling_strategy': 0.3, 'undersampler__sampling_strategy': 0.5}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.68      0.77      9888\n",
            "           1       0.33      0.68      0.45      2354\n",
            "\n",
            "    accuracy                           0.68     12242\n",
            "   macro avg       0.62      0.68      0.61     12242\n",
            "weighted avg       0.79      0.68      0.71     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          6703  3185\n",
            "1           763  1591\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('smote',\n",
            "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
            "                                              m_neighbors='deprecated',\n",
            "                                              n_jobs=1, out_step='deprecated',\n",
            "                                              random_state=None, ratio=None,\n",
            "                                              sampling_strategy='auto',\n",
            "                                              svm_estimator='deprecated')),\n",
            "                                       ('undersampler',\n",
            "                                        RandomUnderSampler(random_state=None,\n",
            "                                                           ratio=None,\n",
            "                                                           replacement=False,\n",
            "                                                           return_ind...\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
            "                         'rfc__min_samples_split': [2, 5, 8, 11],\n",
            "                         'rfc__n_estimators': [100, 150, 200],\n",
            "                         'smote__sampling_strategy': [0.3, 0.4],\n",
            "                         'undersampler__sampling_strategy': [0.5, 0.75]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   53.9s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed:  7.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2797.2878333333338\n",
            "Best parameters found {'rfc__criterion': 'gini', 'rfc__min_samples_split': 11, 'rfc__n_estimators': 200, 'smote__sampling_strategy': 0.3, 'undersampler__sampling_strategy': 0.75}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82      9888\n",
            "           1       0.36      0.57      0.45      2354\n",
            "\n",
            "    accuracy                           0.73     12242\n",
            "   macro avg       0.62      0.67      0.63     12242\n",
            "weighted avg       0.78      0.73      0.75     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          7526  2362\n",
            "1          1003  1351\n",
            "\n",
            "Beginning GridSearchCV for GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('smote',\n",
            "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
            "                                              m_neighbors='deprecated',\n",
            "                                              n_jobs=1, out_step='deprecated',\n",
            "                                              random_state=None, ratio=None,\n",
            "                                              sampling_strategy='auto',\n",
            "                                              svm_estimator='deprecated')),\n",
            "                                       ('undersampler',\n",
            "                                        RandomUnderSampler(random_state=None,\n",
            "                                                           ratio=None,\n",
            "                                                           replacement=False,\n",
            "                                                           return_ind...\n",
            "                                                      use_label_encoder=False,\n",
            "                                                      verbosity=1))],\n",
            "                                verbose=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'smote__sampling_strategy': [0.3, 0.4],\n",
            "                         'undersampler__sampling_strategy': [0.5, 0.75],\n",
            "                         'xgc__learning_rate': [0.01, 0.02],\n",
            "                         'xgc__max_depth': [4, 5, 6, 7]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=make_scorer(f1_score, labels=[1], average=binary),\n",
            "             verbose=1)\n",
            "\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   34.2s\n",
            "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  1.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 12242\n",
            "Total Loss incurred: 2926.4556833333336\n",
            "Best parameters found {'smote__sampling_strategy': 0.3, 'undersampler__sampling_strategy': 0.75, 'xgc__learning_rate': 0.01, 'xgc__max_depth': 4}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.81      9888\n",
            "           1       0.36      0.59      0.45      2354\n",
            "\n",
            "    accuracy                           0.72     12242\n",
            "   macro avg       0.62      0.67      0.63     12242\n",
            "weighted avg       0.78      0.72      0.74     12242\n",
            "\n",
            "Predicted     0     1\n",
            "Has_Won              \n",
            "0          7377  2511\n",
            "1           955  1399\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jddLaS-YadFk",
        "outputId": "bb00f0e4-20e0-40bc-d5f7-d6a74578b3f3"
      },
      "source": [
        "# Obtaining the final scores for each model, after hyperparameter optimisation, with 5-fold cross-validation\n",
        "\n",
        "print(f'Logistic regression score: {np.mean(cross_val_score(logreg_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'Random forest score: {np.mean(cross_val_score(rfc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')\n",
        "print(f'XGBoost score: {np.mean(cross_val_score(xgc_clf.best_estimator_, X_train, y_train, scoring=f1_score_positive, cv=5, n_jobs=-1, verbose=1))}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic regression score: 0.44437658672736513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random forest score: 0.4356327472344958\n",
            "XGBoost score: 0.44489311962617756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UECacSCngKiA"
      },
      "source": [
        "## Final Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bls0zTcnahwA"
      },
      "source": [
        "def betting_loss_cumulative(y_true, y_pred, X=df_dummies):\n",
        "\n",
        "    # Converting y_pred from Pandas series to DataFrame, setting its index to equal y_true, and switching back to Series\n",
        "    y_pred = pd.DataFrame(data=y_pred)\n",
        "    y_pred.set_index(y_true.index, inplace=True)\n",
        "    y_pred = pd.Series(data=y_pred[0], index=y_pred.index)\n",
        "    \n",
        "    profit = []\n",
        "    for i in y_pred.index:\n",
        "        if (y_pred[i] == y_true[i]) and (y_true[i] == 1):\n",
        "            profit.append(X.loc[i, 'P_Avg_Odds'] - 1)\n",
        "        elif (y_pred[i] == y_true[i]) and (y_true[i] == 0):\n",
        "            profit.append(0)\n",
        "        else:\n",
        "            profit.append(-1)\n",
        "\n",
        "    profit = np.array(profit)\n",
        "    profit = profit.cumsum()\n",
        "\n",
        "    return profit"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1i_qiQpFDM"
      },
      "source": [
        "def favorite_predictor(X_test):\n",
        "    '''\n",
        "    Makes the prediction based on who is favorite to win, using the data provided by the betting odds.\n",
        "    The lower betting odds between the two players dictate the player is favorite to win.\n",
        "    '''\n",
        "    y_pred_favorite = np.zeros(len(X_test))\n",
        "    y_pred_favorite[X_test[:,0] <= X_test[:,1]] = 1\n",
        "    \n",
        "    return y_pred_favorite"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxFqLckI-Dqi",
        "outputId": "12a607fd-976c-4263-fd94-2175d6ca4ccf"
      },
      "source": [
        "# Setting the best classification model that we've found\n",
        "# Since there are no pre-processing steps or additional steps required, we won't need a Pipeline\n",
        "\n",
        "xgc_best = xgb.XGBClassifier(tree_method='gpu_hist', \n",
        "                   use_label_encoder=False,\n",
        "                   booster='gbtree',\n",
        "                   subsample=0.8,\n",
        "                   learning_rate=0.02,\n",
        "                   max_depth= 4,\n",
        "                   scale_pos_weight= 4)\n",
        "xgc_best.fit(X_train, y_train)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=4, seed=None,\n",
              "              silent=None, subsample=0.8, tree_method='gpu_hist',\n",
              "              use_label_encoder=False, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO3SEdIYrrv3"
      },
      "source": [
        "y_pred = xgc_best.predict(X_test)\n",
        "y_favorite_pred = favorite_predictor(X_test)\n",
        "y_dummy_pred = dummy.predict(X_test)\n",
        "\n",
        "x_axis = np.arange(1, len(y_test),1)\n",
        "\n",
        "y_best_model_profit = betting_loss_cumulative(y_test, y_pred)\n",
        "y_favorite_profit = betting_loss_cumulative(y_test, y_favorite_pred)\n",
        "y_dummy_profit = betting_loss_cumulative(y_test, y_dummy_pred)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "SR31oXbrJzgm",
        "outputId": "22450dc9-4f87-4286-e569-2e71bedaca9d"
      },
      "source": [
        "x_data = []\n",
        "y1_data = []\n",
        "y2_data = []\n",
        "y3_data = []\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "plt.title('Cumulative Betting Profit (loss) Over Number of Matches')\n",
        "plt.xlabel('Number of matches')\n",
        "plt.ylabel('Profit(loss) in Dollars')\n",
        "ax.set_xlim(0,13000)\n",
        "ax.set_ylim(-4000,1000)\n",
        "line, = ax.plot(0,0, color='green', label='With XGBoost predictions')\n",
        "line2, = ax.plot(0,0, color='blue', label='Prediction based on betting odds favorite')\n",
        "line3, = ax.plot(0,0, color='red', label='Random guess')\n",
        "plt.legend()\n",
        "\n",
        "def animation_frame(i):\n",
        "    x_data.append(x_axis[i])\n",
        "    y1_data.append(y_best_model_profit[i])\n",
        "    y2_data.append(y_favorite_profit[i])\n",
        "    y3_data.append(y_dummy_profit[i])\n",
        "\n",
        "    line.set_xdata(x_data)\n",
        "    line.set_ydata(y1_data)\n",
        "    line2.set_xdata(x_data)\n",
        "    line2.set_ydata(y2_data)\n",
        "    line3.set_xdata(x_data)\n",
        "    line3.set_ydata(y3_data)\n",
        "    return line,\n",
        "\n",
        "animation = FuncAnimation(fig, func=animation_frame, frames=np.arange(0,len(x_axis),6), interval=0.001)\n",
        "animation.save(OUTPUT_DATA_PATH + 'animation.gif', writer='pillow', fps=30)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vHZhSq3_GEp",
        "outputId": "a6afde8e-b976-431c-d9c8-c19c63d552cd"
      },
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "print(pd.crosstab(y_test, y_pred))\n",
        "betting_loss(y_test, y_pred)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.70      0.79      9888\n",
            "           1       0.34      0.65      0.45      2354\n",
            "\n",
            "    accuracy                           0.69     12242\n",
            "   macro avg       0.62      0.68      0.62     12242\n",
            "weighted avg       0.79      0.69      0.72     12242\n",
            "\n",
            "col_0       0     1\n",
            "Has_Won            \n",
            "0        6923  2965\n",
            "1         822  1532\n",
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3131.7144000000008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3131.7144000000008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjtNODypBM2l",
        "outputId": "8a323e14-4295-4528-e979-d20c1b06f59d"
      },
      "source": [
        "print(classification_report(y_test, y_favorite_pred))\n",
        "print(pd.crosstab(y_test, y_favorite_pred))\n",
        "betting_loss(y_test, y_favorite_pred)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.72      0.79      9888\n",
            "           1       0.35      0.64      0.45      2354\n",
            "\n",
            "    accuracy                           0.70     12242\n",
            "   macro avg       0.62      0.68      0.62     12242\n",
            "weighted avg       0.79      0.70      0.73     12242\n",
            "\n",
            "col_0     0.0   1.0\n",
            "Has_Won            \n",
            "0        7079  2809\n",
            "1         849  1505\n",
            "Total number of matches: 12242\n",
            "Total Loss incurred: 3035.7332166666674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3035.7332166666674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCWnfloNG0R7",
        "outputId": "f4e4ccc0-6cdf-4f59-bc08-9fea1cbe8524"
      },
      "source": [
        "print(classification_report(y_test, y_dummy_pred))\n",
        "print(pd.crosstab(y_test, y_dummy_pred))\n",
        "betting_loss(y_test, y_dummy_pred)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.51      0.62      9888\n",
            "           1       0.20      0.51      0.29      2354\n",
            "\n",
            "    accuracy                           0.51     12242\n",
            "   macro avg       0.51      0.51      0.45     12242\n",
            "weighted avg       0.70      0.51      0.56     12242\n",
            "\n",
            "col_0       0     1\n",
            "Has_Won            \n",
            "0        5003  4885\n",
            "1        1147  1207\n",
            "Total number of matches: 12242\n",
            "Total Loss incurred: 4860.80325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4860.80325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    }
  ]
}